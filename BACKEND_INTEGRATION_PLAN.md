# üöÄ Backend Integration Plan - LLM Lab

## üìä **CURRENT STATE ANALYSIS**

### ‚úÖ **EXISTING BACKEND APIs (Production-Ready)**
```javascript
// Core Experiments API
GET    /api/experiments              // List all experiments
GET    /api/experiments/:id          // Get experiment by ID  
POST   /api/experiments              // Create new experiment
PUT    /api/experiments/:id          // Update experiment
DELETE /api/experiments/:id          // Delete experiment

// Response Generation API
POST   /api/responses/generate       // Generate responses for experiment
GET    /api/responses/:experimentId  // Get responses by experiment
GET    /api/responses/single/:id     // Get single response

// Quality Metrics API  
GET    /api/metrics/:responseId      // Get quality metrics
POST   /api/metrics/batch           // Calculate batch metrics
POST   /api/metrics/compare         // Compare metrics

// Export API
GET    /api/export/:experimentId    // Export experiment data
GET    /api/export/:experimentId/csv // Export as CSV

// LLM Provider API
GET    /api/llm/provider            // Get current provider info
POST   /api/llm/provider/switch     // Switch provider
GET    /api/llm/models              // Get available models

// Health & Status
GET    /api/health                  // Health check
```

### üóÉÔ∏è **CURRENT DATABASE SCHEMA**
```sql
-- Experiments Table
CREATE TABLE experiments (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  name TEXT NOT NULL,
  description TEXT,
  prompt TEXT NOT NULL,
  temperature_min REAL NOT NULL DEFAULT 0.1,
  temperature_max REAL NOT NULL DEFAULT 1.0,
  temperature_step REAL NOT NULL DEFAULT 0.1,
  top_p_min REAL NOT NULL DEFAULT 0.1,
  top_p_max REAL NOT NULL DEFAULT 1.0,
  top_p_step REAL NOT NULL DEFAULT 0.1,
  max_tokens INTEGER DEFAULT 150,
  response_count INTEGER DEFAULT 5,
  status TEXT DEFAULT 'draft',
  created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
  updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
);

-- Responses Table
CREATE TABLE responses (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  experiment_id INTEGER NOT NULL,
  content TEXT NOT NULL,
  temperature REAL NOT NULL,
  top_p REAL NOT NULL,
  frequency_penalty REAL DEFAULT 0.0,
  presence_penalty REAL DEFAULT 0.0,
  max_tokens INTEGER,
  model TEXT DEFAULT 'gpt-3.5-turbo',
  prompt_tokens INTEGER,
  completion_tokens INTEGER,
  total_tokens INTEGER,
  response_time REAL,
  created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
  FOREIGN KEY (experiment_id) REFERENCES experiments (id)
);

-- Quality Metrics Table
CREATE TABLE quality_metrics (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  response_id INTEGER NOT NULL,
  coherence_score REAL,
  completeness_score REAL,
  readability_score REAL,
  length_appropriateness_score REAL,
  creativity_score REAL,
  specificity_score REAL,
  overall_score REAL,
  word_count INTEGER,
  sentence_count INTEGER,
  calculated_at DATETIME DEFAULT CURRENT_TIMESTAMP,
  FOREIGN KEY (response_id) REFERENCES responses (id)
);
```

## üé≠ **FRONTEND MOCK DATA ANALYSIS**

### üìç **Major Mock Data Locations**

1. **`frontend/src/components/Dashboard/pages/BatchExperiments.js`** - Extensive mock data:
   ```javascript
   - generateMockResults(count) // Mock parameter test results
   - generateQualityTrends() // Mock quality trend data
   - generateParameterAnalysis() // Mock parameter analysis
   - Mock batch jobs with status, progress, results
   ```

2. **`frontend/src/components/Dashboard/pages/QualityMetrics.js`** - Mock metrics:
   ```javascript
   - mockData.overallStats // Overall quality statistics
   - mockData.metricBreakdown // Individual metric scores
   - mockData.historicalTrends // Quality trends over time
   ```

3. **`frontend/src/components/Dashboard/pages/ParameterTesting.js`** - Mock responses:
   ```javascript
   - Mock LLM response generation
   - Mock quality metrics calculation
   - Mock parameter optimization data
   ```

4. **`frontend/src/components/Dashboard/pages/BatchResultsAnalysis.js`** - Mock analysis:
   ```javascript
   - Comprehensive batch analysis results
   - Parameter optimization insights
   - Quality correlation data
   ```

## ‚ùå **MISSING BACKEND APIs NEEDED BY FRONTEND**

### 1. **BATCH EXPERIMENT APIs** ‚ö†Ô∏è **CRITICAL MISSING**
```javascript
// Batch Operations (NOT IMPLEMENTED)
POST   /api/experiments/batch           // Create batch experiment
GET    /api/experiments/batch           // List batch jobs  
GET    /api/experiments/batch/:id       // Get batch job details
POST   /api/experiments/batch/:id/start // Start batch execution
GET    /api/experiments/batch/:id/status // Get batch status/progress
DELETE /api/experiments/batch/:id       // Cancel/delete batch job

// Batch Analysis (NOT IMPLEMENTED)  
GET    /api/experiments/batch/:id/analysis     // Comprehensive batch analysis
GET    /api/experiments/batch/:id/optimization // Parameter optimization results
GET    /api/experiments/batch/:id/insights     // AI-generated insights
```

### 2. **ADVANCED ANALYTICS APIs** ‚ö†Ô∏è **CRITICAL MISSING**
```javascript
// Quality Analytics (NOT IMPLEMENTED)
GET    /api/analytics/quality/trends    // Quality trends over time
GET    /api/analytics/quality/breakdown // Quality metrics breakdown
GET    /api/analytics/models/comparison // Model performance comparison

// Parameter Analytics (NOT IMPLEMENTED)
GET    /api/analytics/parameters/optimization // Parameter optimization data
GET    /api/analytics/parameters/correlation  // Parameter-quality correlation
GET    /api/analytics/parameters/insights     // Parameter insights
```

### 3. **REAL-TIME PROGRESS APIs** ‚ö†Ô∏è **PARTIALLY IMPLEMENTED**
```javascript
// Server-Sent Events (SSE) - NEEDS ENHANCEMENT
GET    /api/experiments/:id/progress    // Real-time progress updates
GET    /api/experiments/batch/:id/progress // Batch progress updates
```

### 4. **ENHANCED EXPORT APIs** ‚ö†Ô∏è **MISSING FEATURES**
```javascript
// Advanced Export (NOT IMPLEMENTED)
POST   /api/export/batch              // Export batch results
GET    /api/export/analytics/:type    // Export analytics data
POST   /api/export/custom             // Custom export with filters
```

## üîß **REQUIRED DATABASE SCHEMA CHANGES**

### **NEW TABLES NEEDED:**

```sql
-- Batch Experiments Table
CREATE TABLE batch_experiments (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  name TEXT NOT NULL,
  description TEXT,
  prompt TEXT NOT NULL,
  model TEXT DEFAULT 'gpt-3.5-turbo',
  status TEXT DEFAULT 'pending', -- pending, running, completed, failed, cancelled
  progress INTEGER DEFAULT 0,
  total_combinations INTEGER NOT NULL,
  completed_combinations INTEGER DEFAULT 0,
  parameter_ranges TEXT NOT NULL, -- JSON string
  results_summary TEXT, -- JSON string  
  error_message TEXT,
  started_at DATETIME,
  completed_at DATETIME,
  created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
  updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
);

-- Batch Results Table  
CREATE TABLE batch_results (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  batch_experiment_id INTEGER NOT NULL,
  temperature REAL NOT NULL,
  top_p REAL NOT NULL,
  max_tokens INTEGER,
  response_content TEXT NOT NULL,
  quality_scores TEXT NOT NULL, -- JSON string
  usage_stats TEXT, -- JSON string (tokens, cost, etc.)
  response_time REAL,
  created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
  FOREIGN KEY (batch_experiment_id) REFERENCES batch_experiments (id)
);

-- Parameter Insights Table
CREATE TABLE parameter_insights (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  batch_experiment_id INTEGER NOT NULL,
  parameter_name TEXT NOT NULL,
  optimal_value REAL NOT NULL,
  correlation_score REAL,
  insight_text TEXT,
  confidence_score REAL,
  created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
  FOREIGN KEY (batch_experiment_id) REFERENCES batch_experiments (id)
);

-- Quality Analytics Table
CREATE TABLE quality_analytics (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  experiment_id INTEGER,
  batch_experiment_id INTEGER,
  metric_type TEXT NOT NULL, -- coherence, creativity, etc.
  average_score REAL,
  trend_direction TEXT, -- increasing, decreasing, stable
  data_points TEXT, -- JSON array of historical data
  calculated_at DATETIME DEFAULT CURRENT_TIMESTAMP
);
```

### **EXISTING TABLE MODIFICATIONS:**

```sql
-- Add to experiments table
ALTER TABLE experiments ADD COLUMN experiment_type TEXT DEFAULT 'single'; -- single, batch
ALTER TABLE experiments ADD COLUMN tags TEXT; -- JSON array of tags
ALTER TABLE experiments ADD COLUMN favorited BOOLEAN DEFAULT FALSE;
ALTER TABLE experiments ADD COLUMN archived BOOLEAN DEFAULT FALSE;

-- Add to responses table  
ALTER TABLE responses ADD COLUMN batch_experiment_id INTEGER;
ALTER TABLE responses ADD COLUMN cost REAL; -- API cost
ALTER TABLE responses ADD COLUMN error_message TEXT;

-- Add to quality_metrics table
ALTER TABLE quality_metrics ADD COLUMN confidence_score REAL;
ALTER TABLE quality_metrics ADD COLUMN analysis_version TEXT DEFAULT '1.0';
```

## üìã **STEP-BY-STEP INTEGRATION PLAN**

### **PHASE 1: DATABASE SCHEMA UPDATES** ‚è±Ô∏è **Week 1**

#### 1.1 Create Database Migration Script
```sql
-- File: backend/migrations/001_batch_experiments.sql
-- Add new tables and modify existing ones
```

#### 1.2 Update Database Models
- [ ] Create `BatchExperiment.js` model
- [ ] Create `BatchResult.js` model  
- [ ] Create `ParameterInsight.js` model
- [ ] Create `QualityAnalytics.js` model
- [ ] Update existing models with new fields

#### 1.3 Test Database Changes
- [ ] Run migration scripts
- [ ] Verify table creation
- [ ] Test foreign key constraints
- [ ] Validate data integrity

### **PHASE 2: BATCH EXPERIMENT BACKEND APIs** ‚è±Ô∏è **Week 2-3**

#### 2.1 Create Batch Experiment Controllers
```javascript
// File: backend/controllers/batchExperimentController.js
```

#### 2.2 Implement Core Batch APIs
- [ ] `POST /api/experiments/batch` - Create batch experiment
- [ ] `GET /api/experiments/batch` - List all batch jobs
- [ ] `GET /api/experiments/batch/:id` - Get batch details
- [ ] `POST /api/experiments/batch/:id/start` - Start execution
- [ ] `GET /api/experiments/batch/:id/status` - Get status/progress
- [ ] `DELETE /api/experiments/batch/:id` - Cancel/delete batch

#### 2.3 Implement Batch Processing Logic
- [ ] Parameter combination generator
- [ ] Asynchronous batch execution
- [ ] Progress tracking system
- [ ] Error handling and recovery
- [ ] Results aggregation

#### 2.4 Add Real-time Progress Updates
- [ ] Server-Sent Events (SSE) implementation
- [ ] WebSocket alternative consideration
- [ ] Progress broadcasting system

### **PHASE 3: ANALYTICS BACKEND APIs** ‚è±Ô∏è **Week 4-5**

#### 3.1 Quality Analytics Controllers
```javascript
// File: backend/controllers/analyticsController.js
```

#### 3.2 Implement Analytics APIs
- [ ] `GET /api/analytics/quality/trends` - Quality trends
- [ ] `GET /api/analytics/quality/breakdown` - Metrics breakdown
- [ ] `GET /api/analytics/models/comparison` - Model comparison
- [ ] `GET /api/analytics/parameters/optimization` - Parameter optimization
- [ ] `GET /api/analytics/parameters/correlation` - Correlation analysis
- [ ] `GET /api/analytics/parameters/insights` - AI insights

#### 3.3 Advanced Analytics Services
- [ ] Quality trend calculation service
- [ ] Parameter correlation analysis
- [ ] Statistical analysis utilities
- [ ] Data aggregation services

### **PHASE 4: ENHANCED EXPORT SYSTEM** ‚è±Ô∏è **Week 6**

#### 4.1 Enhanced Export Controllers
```javascript
// File: backend/controllers/exportController.js
```

#### 4.2 Implement Advanced Export APIs
- [ ] `POST /api/export/batch` - Export batch results
- [ ] `GET /api/export/analytics/:type` - Export analytics
- [ ] `POST /api/export/custom` - Custom exports with filters

#### 4.3 Export Format Support
- [ ] CSV export with custom fields
- [ ] JSON export with nested data
- [ ] Excel export for complex datasets
- [ ] PDF report generation

### **PHASE 5: FRONTEND INTEGRATION** ‚è±Ô∏è **Week 7-8**

#### 5.1 Replace Mock Data with Real APIs

##### 5.1.1 BatchExperiments.js Updates
- [ ] Replace `generateMockResults()` with real API calls
- [ ] Integrate real-time progress updates
- [ ] Connect batch creation with backend
- [ ] Implement real batch status tracking

##### 5.1.2 QualityMetrics.js Updates  
- [ ] Replace mock analytics with real data
- [ ] Connect to quality analytics APIs
- [ ] Implement historical trends from database
- [ ] Add real-time metric calculations

##### 5.1.3 ParameterTesting.js Updates
- [ ] Connect to real LLM APIs
- [ ] Integrate quality metrics calculation
- [ ] Add parameter optimization backend calls
- [ ] Replace mock response generation

##### 5.1.4 BatchResultsAnalysis.js Updates
- [ ] Connect to batch analysis APIs
- [ ] Integrate parameter optimization data
- [ ] Add real correlation analysis
- [ ] Connect to insights generation

#### 5.2 API Service Layer Updates
```javascript
// File: frontend/src/services/api.js
// Add new API endpoints and remove mock data fallbacks
```

#### 5.3 Add Error Handling and Loading States
- [ ] Proper error boundaries for API failures
- [ ] Loading states for long-running operations
- [ ] Retry mechanisms for failed requests
- [ ] User feedback for API errors

### **PHASE 6: TESTING & OPTIMIZATION** ‚è±Ô∏è **Week 9-10**

#### 6.1 Backend API Testing
- [ ] Unit tests for all new controllers
- [ ] Integration tests for batch processing
- [ ] Load testing for concurrent batch jobs
- [ ] Error scenario testing

#### 6.2 Frontend Integration Testing
- [ ] Component testing with real APIs
- [ ] End-to-end testing for complete workflows
- [ ] Performance testing for large datasets
- [ ] User acceptance testing

#### 6.3 Performance Optimization
- [ ] Database query optimization
- [ ] API response caching
- [ ] Frontend data caching
- [ ] Batch processing optimization

### **PHASE 7: PRODUCTION DEPLOYMENT** ‚è±Ô∏è **Week 11-12**

#### 7.1 Environment Configuration
- [ ] Production database setup
- [ ] Environment-specific API configurations
- [ ] Logging and monitoring setup
- [ ] Error tracking integration

#### 7.2 Deployment Pipeline
- [ ] CI/CD pipeline for backend APIs
- [ ] Database migration automation
- [ ] Frontend build optimization
- [ ] Health check endpoints

#### 7.3 Monitoring & Alerts
- [ ] API performance monitoring
- [ ] Database performance monitoring
- [ ] Error rate alerts
- [ ] Batch job failure notifications

## üîç **DETAILED API SPECIFICATIONS**

### **Batch Experiment APIs**

#### Create Batch Experiment
```javascript
POST /api/experiments/batch
Content-Type: application/json

{
  "name": "Temperature Analysis Batch",
  "description": "Testing temperature variations",
  "prompt": "Write a creative story about...",
  "model": "gpt-4",
  "parameter_ranges": {
    "temperature": { "min": 0.1, "max": 1.0, "step": 0.1 },
    "top_p": { "min": 0.8, "max": 1.0, "step": 0.05 },
    "max_tokens": [150, 300, 500]
  },
  "response_count": 3
}

Response:
{
  "id": 123,
  "status": "pending",
  "total_combinations": 72,
  "estimated_duration": "45 minutes",
  "created_at": "2025-10-29T10:00:00Z"
}
```

#### Get Batch Status
```javascript
GET /api/experiments/batch/123/status

Response:
{
  "id": 123,
  "status": "running",
  "progress": 65,
  "completed_combinations": 47,
  "total_combinations": 72,
  "current_parameters": {
    "temperature": 0.7,
    "top_p": 0.95,
    "max_tokens": 300
  },
  "estimated_completion": "2025-10-29T10:35:00Z",
  "results_preview": {
    "best_quality_score": 87.5,
    "average_quality_score": 76.2,
    "optimal_parameters": {
      "temperature": 0.6,
      "top_p": 0.9
    }
  }
}
```

### **Analytics APIs**

#### Quality Trends
```javascript
GET /api/analytics/quality/trends?timeframe=30d&experiment_type=batch

Response:
{
  "timeframe": "30d",
  "data_points": [
    {
      "date": "2025-10-01",
      "average_quality": 78.5,
      "experiment_count": 12,
      "metrics": {
        "coherence": 82.1,
        "creativity": 74.3,
        "readability": 79.2
      }
    }
  ],
  "trends": {
    "overall_direction": "increasing",
    "improvement_rate": 2.3,
    "best_performing_period": "2025-10-25 to 2025-10-29"
  }
}
```

#### Parameter Optimization
```javascript
GET /api/analytics/parameters/optimization?batch_id=123

Response:
{
  "batch_id": 123,
  "optimal_parameters": {
    "temperature": {
      "value": 0.6,
      "confidence": 0.85,
      "quality_impact": "+12.3%"
    },
    "top_p": {
      "value": 0.9,
      "confidence": 0.78,
      "quality_impact": "+8.7%"
    }
  },
  "parameter_correlations": [
    {
      "parameter_1": "temperature",
      "parameter_2": "creativity_score",
      "correlation": 0.73,
      "significance": "high"
    }
  ],
  "recommendations": [
    {
      "parameter": "temperature",
      "current_range": "0.1-1.0",
      "recommended_range": "0.5-0.8",
      "reasoning": "Values outside this range show diminishing returns"
    }
  ]
}
```

## üéØ **SUCCESS METRICS**

### **Technical Metrics**
- [ ] 100% mock data replaced with real APIs
- [ ] API response time < 500ms (95th percentile)
- [ ] Batch processing throughput > 10 combinations/minute
- [ ] Zero data loss during batch operations
- [ ] 99.9% API uptime

### **User Experience Metrics**
- [ ] Real-time progress updates with < 2s latency
- [ ] Smooth UI transitions during data loading
- [ ] Error recovery without data loss
- [ ] Export completion in < 30 seconds for typical datasets

### **Data Quality Metrics**
- [ ] Accurate quality metrics calculation
- [ ] Consistent parameter correlation analysis
- [ ] Reliable trend calculations
- [ ] Proper data aggregation across time periods

## üö® **CRITICAL CONSIDERATIONS**

### **Performance**
- Batch operations may run for hours - need proper queuing
- Large datasets require pagination and streaming
- Real-time updates need efficient data structures
- Database indexes critical for analytics queries

### **Data Integrity**
- Batch operations must be atomic or properly recoverable
- Quality metrics must be consistently calculated
- Parameter correlations need statistical validation
- Export data must match displayed data exactly

### **User Experience**
- Graceful degradation when APIs are slow/unavailable
- Clear progress indicators for long operations
- Intuitive error messages and recovery options
- Responsive design for all new components

### **Scalability**
- Queue system for batch processing
- Database connection pooling
- API rate limiting and throttling
- Caching strategy for analytics data

## üìÖ **TIMELINE SUMMARY**

| Phase | Duration | Key Deliverables |
|-------|----------|------------------|
| 1 | Week 1 | Database schema updates |
| 2 | Week 2-3 | Batch experiment APIs |
| 3 | Week 4-5 | Analytics APIs |
| 4 | Week 6 | Enhanced export system |
| 5 | Week 7-8 | Frontend integration |
| 6 | Week 9-10 | Testing & optimization |
| 7 | Week 11-12 | Production deployment |

**Total Timeline: 12 weeks (3 months)**

## üîó **DEPENDENCIES**

### **External Dependencies**
- LLM API rate limits and costs
- Database performance under load
- Frontend component performance with real data

### **Internal Dependencies**
- Backend API development before frontend integration
- Database migration before API implementation
- Testing completion before production deployment

## üìã **NEXT IMMEDIATE ACTIONS**

1. **Create database migration scripts** (Priority: HIGH)
2. **Set up development environment for backend APIs** (Priority: HIGH)
3. **Design batch processing queue system** (Priority: MEDIUM)
4. **Plan API testing strategy** (Priority: MEDIUM)
5. **Review frontend components for API integration points** (Priority: LOW)

---

**Document Version:** 1.0  
**Last Updated:** October 29, 2025  
**Next Review:** November 5, 2025
